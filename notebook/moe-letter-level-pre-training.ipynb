{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/MorningStarTM/Mixture-of-LLM-Expert.git","metadata":{"execution":{"iopub.status.busy":"2024-07-29T13:54:01.511796Z","iopub.execute_input":"2024-07-29T13:54:01.512493Z","iopub.status.idle":"2024-07-29T13:54:03.168111Z","shell.execute_reply.started":"2024-07-29T13:54:01.512457Z","shell.execute_reply":"2024-07-29T13:54:03.167001Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'Mixture-of-LLM-Expert'...\nremote: Enumerating objects: 97, done.\u001b[K\nremote: Counting objects: 100% (97/97), done.\u001b[K\nremote: Compressing objects: 100% (54/54), done.\u001b[K\nremote: Total 97 (delta 43), reused 89 (delta 39), pack-reused 0\u001b[K\nUnpacking objects: 100% (97/97), 16.15 KiB | 636.00 KiB/s, done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/working/Mixture-of-LLM-Expert","metadata":{"execution":{"iopub.status.busy":"2024-07-29T13:54:03.170130Z","iopub.execute_input":"2024-07-29T13:54:03.170463Z","iopub.status.idle":"2024-07-29T13:54:03.177663Z","shell.execute_reply.started":"2024-07-29T13:54:03.170416Z","shell.execute_reply":"2024-07-29T13:54:03.176596Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/working/Mixture-of-LLM-Expert\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-07-29T13:54:03.178933Z","iopub.execute_input":"2024-07-29T13:54:03.179193Z","iopub.status.idle":"2024-07-29T13:54:04.182281Z","shell.execute_reply.started":"2024-07-29T13:54:03.179171Z","shell.execute_reply":"2024-07-29T13:54:04.181377Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"LICENSE  MoE  Models  README.md  Tokenizer  Utils\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport re\nimport json\nfrom MoE import SparseMoELanguageModel, kaiming_init_weights\nfrom Utils import model_params\nfrom Tokenizer import WordLevelTokenizer, extract_and_save_text, LetterLevelTokenizer\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-07-29T13:54:42.611430Z","iopub.execute_input":"2024-07-29T13:54:42.611971Z","iopub.status.idle":"2024-07-29T13:54:42.617000Z","shell.execute_reply.started":"2024-07-29T13:54:42.611939Z","shell.execute_reply":"2024-07-29T13:54:42.615979Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice\nmax_iters = 100000\nlearning_rate = 3e-4\nblock_size = 8\nbatch_size = 8\neval_iters = 500\nn_emb = 384\nn_layers = 6\nn_head = 6","metadata":{"execution":{"iopub.status.busy":"2024-07-29T13:54:11.158490Z","iopub.execute_input":"2024-07-29T13:54:11.159060Z","iopub.status.idle":"2024-07-29T13:54:11.164552Z","shell.execute_reply.started":"2024-07-29T13:54:11.159029Z","shell.execute_reply":"2024-07-29T13:54:11.163517Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"csv_file_path = '/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv'  # Replace with your CSV file path\noutput_directory = '/kaggle/working/'  # Replace with your desired output directory\n\nextract_and_save_text(csv_file_path, output_directory)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T13:54:20.962760Z","iopub.execute_input":"2024-07-29T13:54:20.965721Z","iopub.status.idle":"2024-07-29T13:54:22.469273Z","shell.execute_reply.started":"2024-07-29T13:54:20.965680Z","shell.execute_reply":"2024-07-29T13:54:22.468497Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"with open(\"/kaggle/working/articles.txt\", \"rb\") as txt:\n    texts = txt.read()","metadata":{"execution":{"iopub.status.busy":"2024-07-29T13:54:22.470814Z","iopub.execute_input":"2024-07-29T13:54:22.471095Z","iopub.status.idle":"2024-07-29T13:54:22.498431Z","shell.execute_reply.started":"2024-07-29T13:54:22.471071Z","shell.execute_reply":"2024-07-29T13:54:22.497558Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"chars = sorted(list(set(texts.decode())))\nvocab_size = len(chars)\nprint(''.join(chars))\nprint(vocab_size)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T13:54:23.212356Z","iopub.execute_input":"2024-07-29T13:54:23.212748Z","iopub.status.idle":"2024-07-29T13:54:24.002736Z","shell.execute_reply.started":"2024-07-29T13:54:23.212719Z","shell.execute_reply":"2024-07-29T13:54:24.001712Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\t\n !\"#$%&'()*+,-./0123456789:;<=?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]_`abcdefghijklmnopqrstuvwxyz|}~ £¥©«¬­®°±´µ·¹º»¼½¾ÁÂÄÅÈÉÓÖ×ØÛÜßàáâãäåçèéêëíîïðñòóôö÷øúûüāăćčēęğīİıłńōřŚśşŠšūŷžș˚ΕΗΘΛΝΣΤΦβμ܎ღạ​‎‏‐‑–—‘’“”•…‪‬ ⁄⁰€™↑■●♥❤ﬂ️－�💗\n218\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = LetterLevelTokenizer()","metadata":{"execution":{"iopub.status.busy":"2024-07-29T13:54:47.080793Z","iopub.execute_input":"2024-07-29T13:54:47.081144Z","iopub.status.idle":"2024-07-29T13:54:47.085542Z","shell.execute_reply.started":"2024-07-29T13:54:47.081116Z","shell.execute_reply":"2024-07-29T13:54:47.084595Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"temp = \"Im the President of the America.\"\n\ntokens = tokenizer.tokenize(temp)\nprint(\"Tokens:\", tokens)  # Output: Tokens: [index values representing each word]\n\noriginal_text = tokenizer.detokenize(tokens)\nprint(\"Detokenized text:\", original_text)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T13:54:48.817309Z","iopub.execute_input":"2024-07-29T13:54:48.817699Z","iopub.status.idle":"2024-07-29T13:54:48.823787Z","shell.execute_reply.started":"2024-07-29T13:54:48.817670Z","shell.execute_reply":"2024-07-29T13:54:48.822838Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Tokens: [34, 12, 94, 19, 7, 4, 94, 41, 17, 4, 18, 8, 3, 4, 13, 19, 94, 14, 5, 94, 19, 7, 4, 94, 26, 12, 4, 17, 8, 2, 0, 75]\nDetokenized text: Im the President of the America.\n","output_type":"stream"}]},{"cell_type":"code","source":"data = tokenizer.tokenize(texts.decode())","metadata":{"execution":{"iopub.status.busy":"2024-07-29T13:54:59.019002Z","iopub.execute_input":"2024-07-29T13:54:59.019398Z","iopub.status.idle":"2024-07-29T13:55:08.057652Z","shell.execute_reply.started":"2024-07-29T13:54:59.019369Z","shell.execute_reply":"2024-07-29T13:55:08.056586Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"encoded_data = torch.tensor(data, dtype=torch.long)\nprint(encoded_data.shape, encoded_data.dtype)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T13:55:16.549641Z","iopub.execute_input":"2024-07-29T13:55:16.550274Z","iopub.status.idle":"2024-07-29T13:55:22.917416Z","shell.execute_reply.started":"2024-07-29T13:55:16.550246Z","shell.execute_reply":"2024-07-29T13:55:22.916290Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"torch.Size([45489315]) torch.int64\n","output_type":"stream"}]},{"cell_type":"code","source":"n = int(0.9*len(encoded_data))\ntrain_data = encoded_data[:n]\nval_data = encoded_data[n:]\n\nprint(f\"Training tokens : {len(train_data)}  --- Validation tokens : {len(val_data)}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-29T13:55:30.938879Z","iopub.execute_input":"2024-07-29T13:55:30.939237Z","iopub.status.idle":"2024-07-29T13:55:30.956842Z","shell.execute_reply.started":"2024-07-29T13:55:30.939209Z","shell.execute_reply":"2024-07-29T13:55:30.955888Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Training tokens : 40940383  --- Validation tokens : 4548932\n","output_type":"stream"}]},{"cell_type":"code","source":"x = train_data[:block_size]\ny = train_data[1:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target: {target}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-29T13:55:32.446333Z","iopub.execute_input":"2024-07-29T13:55:32.447022Z","iopub.status.idle":"2024-07-29T13:55:32.465726Z","shell.execute_reply.started":"2024-07-29T13:55:32.446989Z","shell.execute_reply":"2024-07-29T13:55:32.464718Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"when input is tensor([30]) the target: 21\nwhen input is tensor([30, 21]) the target: 4\nwhen input is tensor([30, 21,  4]) the target: 17\nwhen input is tensor([30, 21,  4, 17]) the target: 94\nwhen input is tensor([30, 21,  4, 17, 94]) the target: 13\nwhen input is tensor([30, 21,  4, 17, 94, 13]) the target: 14\nwhen input is tensor([30, 21,  4, 17, 94, 13, 14]) the target: 19\nwhen input is tensor([30, 21,  4, 17, 94, 13, 14, 19]) the target: 8\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.manual_seed(1337)\n\ndef get_batch(split):\n    data = train_data if split == \"train\" else val_data\n    ix = torch.randint(len(encoded_data) - block_size, (batch_size,))\n    x = torch.stack([encoded_data[i:i+block_size] for i in ix])\n    y = torch.stack([encoded_data[i+1:i+block_size+1] for i in ix])\n    return x, y\n\nxb, yb = get_batch('train')\nprint(\"Inputs: \")\nprint(xb)\nprint(\"Targets: \")\nprint(yb)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T13:55:34.689863Z","iopub.execute_input":"2024-07-29T13:55:34.690787Z","iopub.status.idle":"2024-07-29T13:55:34.722091Z","shell.execute_reply.started":"2024-07-29T13:55:34.690743Z","shell.execute_reply":"2024-07-29T13:55:34.721207Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Inputs: \ntensor([[18, 94,  1,  8, 17, 19,  7,  3],\n        [46, 13,  8, 21,  4, 17, 18,  8],\n        [19, 94,  7,  0,  3, 94, 19,  7],\n        [ 8, 14, 13, 94, 17,  4, 12,  0],\n        [ 6, 14,  8, 13,  6, 94,  0, 94],\n        [ 3,  4,  0, 94, 22,  7,  4, 17],\n        [19,  4, 15,  7,  4, 13, 94, 44],\n        [75, 68, 94, 31, 14, 17, 94,  2]])\nTargets: \ntensor([[94,  1,  8, 17, 19,  7,  3,  0],\n        [13,  8, 21,  4, 17, 18,  8, 19],\n        [94,  7,  0,  3, 94, 19,  7,  4],\n        [14, 13, 94, 17,  4, 12,  0,  8],\n        [14,  8, 13,  6, 94,  0, 94, 53],\n        [ 4,  0, 94, 22,  7,  4, 17,  4],\n        [ 4, 15,  7,  4, 13, 94, 44, 12],\n        [68, 94, 31, 14, 17, 94,  2, 14]])\n","output_type":"stream"}]},{"cell_type":"code","source":"model = SparseMoELanguageModel(vocab_size)\nmodel.apply(kaiming_init_weights)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T13:55:50.309387Z","iopub.execute_input":"2024-07-29T13:55:50.310316Z","iopub.status.idle":"2024-07-29T13:55:52.117267Z","shell.execute_reply.started":"2024-07-29T13:55:50.310274Z","shell.execute_reply":"2024-07-29T13:55:52.116379Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"SparseMoELanguageModel(\n  (token_embedding_table): Embedding(218, 368)\n  (position_embedding_table): Embedding(32, 368)\n  (blocks): Sequential(\n    (0): Block(\n      (sa): MultiHeadAttention(\n        (heads): ModuleList(\n          (0-7): 8 x Head(\n            (key): Linear(in_features=368, out_features=46, bias=False)\n            (query): Linear(in_features=368, out_features=46, bias=False)\n            (value): Linear(in_features=368, out_features=46, bias=False)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (proj): Linear(in_features=368, out_features=368, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (smoe): SparseMoE(\n        (router): NoisyTopkRouter(\n          (topkroute_linear): Linear(in_features=368, out_features=8, bias=True)\n          (noise_linear): Linear(in_features=368, out_features=8, bias=True)\n        )\n        (experts): ModuleList(\n          (0-7): 8 x Expert(\n            (net): Sequential(\n              (0): Linear(in_features=368, out_features=1472, bias=True)\n              (1): ReLU()\n              (2): Linear(in_features=1472, out_features=368, bias=True)\n              (3): Dropout(p=0.2, inplace=False)\n            )\n          )\n        )\n      )\n      (ln1): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n      (ln2): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n    )\n    (1): Block(\n      (sa): MultiHeadAttention(\n        (heads): ModuleList(\n          (0-7): 8 x Head(\n            (key): Linear(in_features=368, out_features=46, bias=False)\n            (query): Linear(in_features=368, out_features=46, bias=False)\n            (value): Linear(in_features=368, out_features=46, bias=False)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (proj): Linear(in_features=368, out_features=368, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (smoe): SparseMoE(\n        (router): NoisyTopkRouter(\n          (topkroute_linear): Linear(in_features=368, out_features=8, bias=True)\n          (noise_linear): Linear(in_features=368, out_features=8, bias=True)\n        )\n        (experts): ModuleList(\n          (0-7): 8 x Expert(\n            (net): Sequential(\n              (0): Linear(in_features=368, out_features=1472, bias=True)\n              (1): ReLU()\n              (2): Linear(in_features=1472, out_features=368, bias=True)\n              (3): Dropout(p=0.2, inplace=False)\n            )\n          )\n        )\n      )\n      (ln1): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n      (ln2): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n    )\n    (2): Block(\n      (sa): MultiHeadAttention(\n        (heads): ModuleList(\n          (0-7): 8 x Head(\n            (key): Linear(in_features=368, out_features=46, bias=False)\n            (query): Linear(in_features=368, out_features=46, bias=False)\n            (value): Linear(in_features=368, out_features=46, bias=False)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (proj): Linear(in_features=368, out_features=368, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (smoe): SparseMoE(\n        (router): NoisyTopkRouter(\n          (topkroute_linear): Linear(in_features=368, out_features=8, bias=True)\n          (noise_linear): Linear(in_features=368, out_features=8, bias=True)\n        )\n        (experts): ModuleList(\n          (0-7): 8 x Expert(\n            (net): Sequential(\n              (0): Linear(in_features=368, out_features=1472, bias=True)\n              (1): ReLU()\n              (2): Linear(in_features=1472, out_features=368, bias=True)\n              (3): Dropout(p=0.2, inplace=False)\n            )\n          )\n        )\n      )\n      (ln1): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n      (ln2): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n    )\n    (3): Block(\n      (sa): MultiHeadAttention(\n        (heads): ModuleList(\n          (0-7): 8 x Head(\n            (key): Linear(in_features=368, out_features=46, bias=False)\n            (query): Linear(in_features=368, out_features=46, bias=False)\n            (value): Linear(in_features=368, out_features=46, bias=False)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (proj): Linear(in_features=368, out_features=368, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (smoe): SparseMoE(\n        (router): NoisyTopkRouter(\n          (topkroute_linear): Linear(in_features=368, out_features=8, bias=True)\n          (noise_linear): Linear(in_features=368, out_features=8, bias=True)\n        )\n        (experts): ModuleList(\n          (0-7): 8 x Expert(\n            (net): Sequential(\n              (0): Linear(in_features=368, out_features=1472, bias=True)\n              (1): ReLU()\n              (2): Linear(in_features=1472, out_features=368, bias=True)\n              (3): Dropout(p=0.2, inplace=False)\n            )\n          )\n        )\n      )\n      (ln1): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n      (ln2): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n    )\n    (4): Block(\n      (sa): MultiHeadAttention(\n        (heads): ModuleList(\n          (0-7): 8 x Head(\n            (key): Linear(in_features=368, out_features=46, bias=False)\n            (query): Linear(in_features=368, out_features=46, bias=False)\n            (value): Linear(in_features=368, out_features=46, bias=False)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (proj): Linear(in_features=368, out_features=368, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (smoe): SparseMoE(\n        (router): NoisyTopkRouter(\n          (topkroute_linear): Linear(in_features=368, out_features=8, bias=True)\n          (noise_linear): Linear(in_features=368, out_features=8, bias=True)\n        )\n        (experts): ModuleList(\n          (0-7): 8 x Expert(\n            (net): Sequential(\n              (0): Linear(in_features=368, out_features=1472, bias=True)\n              (1): ReLU()\n              (2): Linear(in_features=1472, out_features=368, bias=True)\n              (3): Dropout(p=0.2, inplace=False)\n            )\n          )\n        )\n      )\n      (ln1): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n      (ln2): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n    )\n    (5): Block(\n      (sa): MultiHeadAttention(\n        (heads): ModuleList(\n          (0-7): 8 x Head(\n            (key): Linear(in_features=368, out_features=46, bias=False)\n            (query): Linear(in_features=368, out_features=46, bias=False)\n            (value): Linear(in_features=368, out_features=46, bias=False)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (proj): Linear(in_features=368, out_features=368, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (smoe): SparseMoE(\n        (router): NoisyTopkRouter(\n          (topkroute_linear): Linear(in_features=368, out_features=8, bias=True)\n          (noise_linear): Linear(in_features=368, out_features=8, bias=True)\n        )\n        (experts): ModuleList(\n          (0-7): 8 x Expert(\n            (net): Sequential(\n              (0): Linear(in_features=368, out_features=1472, bias=True)\n              (1): ReLU()\n              (2): Linear(in_features=1472, out_features=368, bias=True)\n              (3): Dropout(p=0.2, inplace=False)\n            )\n          )\n        )\n      )\n      (ln1): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n      (ln2): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n    )\n    (6): Block(\n      (sa): MultiHeadAttention(\n        (heads): ModuleList(\n          (0-7): 8 x Head(\n            (key): Linear(in_features=368, out_features=46, bias=False)\n            (query): Linear(in_features=368, out_features=46, bias=False)\n            (value): Linear(in_features=368, out_features=46, bias=False)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (proj): Linear(in_features=368, out_features=368, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (smoe): SparseMoE(\n        (router): NoisyTopkRouter(\n          (topkroute_linear): Linear(in_features=368, out_features=8, bias=True)\n          (noise_linear): Linear(in_features=368, out_features=8, bias=True)\n        )\n        (experts): ModuleList(\n          (0-7): 8 x Expert(\n            (net): Sequential(\n              (0): Linear(in_features=368, out_features=1472, bias=True)\n              (1): ReLU()\n              (2): Linear(in_features=1472, out_features=368, bias=True)\n              (3): Dropout(p=0.2, inplace=False)\n            )\n          )\n        )\n      )\n      (ln1): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n      (ln2): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n    )\n    (7): Block(\n      (sa): MultiHeadAttention(\n        (heads): ModuleList(\n          (0-7): 8 x Head(\n            (key): Linear(in_features=368, out_features=46, bias=False)\n            (query): Linear(in_features=368, out_features=46, bias=False)\n            (value): Linear(in_features=368, out_features=46, bias=False)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (proj): Linear(in_features=368, out_features=368, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (smoe): SparseMoE(\n        (router): NoisyTopkRouter(\n          (topkroute_linear): Linear(in_features=368, out_features=8, bias=True)\n          (noise_linear): Linear(in_features=368, out_features=8, bias=True)\n        )\n        (experts): ModuleList(\n          (0-7): 8 x Expert(\n            (net): Sequential(\n              (0): Linear(in_features=368, out_features=1472, bias=True)\n              (1): ReLU()\n              (2): Linear(in_features=1472, out_features=368, bias=True)\n              (3): Dropout(p=0.2, inplace=False)\n            )\n          )\n        )\n      )\n      (ln1): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n      (ln2): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (ln_f): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n  (lm_head): Linear(in_features=368, out_features=218, bias=True)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Model paramters","metadata":{}},{"cell_type":"code","source":"model_params(model)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T13:56:08.070643Z","iopub.execute_input":"2024-07-29T13:56:08.071017Z","iopub.status.idle":"2024-07-29T13:56:08.082923Z","shell.execute_reply.started":"2024-07-29T13:56:08.070992Z","shell.execute_reply":"2024-07-29T13:56:08.082058Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Total parameters: 74,023,546\nTrainable parameters: 74,023,546\nNon-trainable parameters: 0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Support Function","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\ndef estimate_loss():\n    out = {}\n    model.eval()\n    for split in ['train', 'val']:\n        losses = torch.zeros(eval_iters)\n        for k in range(eval_iters):\n            X, Y = get_batch(split)\n            X, Y = X.to(device), Y.to(device)\n            logits, loss = model(X, Y)\n            losses[k] = loss.item()\n        out[split] = losses.mean()\n    model.train()\n    return out","metadata":{"execution":{"iopub.status.busy":"2024-07-29T13:56:11.953542Z","iopub.execute_input":"2024-07-29T13:56:11.954151Z","iopub.status.idle":"2024-07-29T13:56:11.960320Z","shell.execute_reply.started":"2024-07-29T13:56:11.954117Z","shell.execute_reply":"2024-07-29T13:56:11.959303Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n\nfor iter in range(max_iters):\n    if iter % eval_iters == 0:\n        losses = estimate_loss()\n        print(f\"steps: {iter} train loss: {losses['train']} val loss: {losses['val']}\")\n        \n    xb, yb = get_batch('train')\n    xb = xb.to(device)\n    yb = yb.to(device)\n\n    logits, loss = model.forward(xb, yb)\n    optimizer.zero_grad(set_to_none=True)\n    loss.backward()\n    optimizer.step()\nprint(loss.item())","metadata":{"execution":{"iopub.status.busy":"2024-07-29T13:56:14.248189Z","iopub.execute_input":"2024-07-29T13:56:14.248882Z","iopub.status.idle":"2024-07-29T16:09:48.067953Z","shell.execute_reply.started":"2024-07-29T13:56:14.248848Z","shell.execute_reply":"2024-07-29T16:09:48.066487Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"steps: 0 train loss: 6.797354698181152 val loss: 6.806445598602295\nsteps: 500 train loss: 2.5807409286499023 val loss: 2.567488193511963\nsteps: 1000 train loss: 2.4178872108459473 val loss: 2.414222240447998\nsteps: 1500 train loss: 2.3510682582855225 val loss: 2.3578083515167236\nsteps: 2000 train loss: 2.359004020690918 val loss: 2.334740161895752\nsteps: 2500 train loss: 2.2673230171203613 val loss: 2.250094413757324\nsteps: 3000 train loss: 2.2315187454223633 val loss: 2.232961654663086\nsteps: 3500 train loss: 2.2234010696411133 val loss: 2.2287089824676514\nsteps: 4000 train loss: 2.1672251224517822 val loss: 2.1592421531677246\nsteps: 4500 train loss: 2.1866283416748047 val loss: 2.18245792388916\nsteps: 5000 train loss: 2.127903699874878 val loss: 2.1395297050476074\nsteps: 5500 train loss: 2.1221275329589844 val loss: 2.1430952548980713\nsteps: 6000 train loss: 2.1232824325561523 val loss: 2.121630907058716\nsteps: 6500 train loss: 2.103116273880005 val loss: 2.1051766872406006\nsteps: 7000 train loss: 2.1034703254699707 val loss: 2.0937299728393555\nsteps: 7500 train loss: 2.0859711170196533 val loss: 2.0936834812164307\nsteps: 8000 train loss: 2.0769431591033936 val loss: 2.0709078311920166\nsteps: 8500 train loss: 2.043668270111084 val loss: 2.0712926387786865\nsteps: 9000 train loss: 2.046039342880249 val loss: 2.0523412227630615\nsteps: 9500 train loss: 2.0604870319366455 val loss: 2.043227434158325\nsteps: 10000 train loss: 2.0388693809509277 val loss: 2.0383386611938477\nsteps: 10500 train loss: 2.029123544692993 val loss: 2.0373573303222656\nsteps: 11000 train loss: 2.0267114639282227 val loss: 2.0091166496276855\nsteps: 11500 train loss: 2.013864040374756 val loss: 2.0137689113616943\nsteps: 12000 train loss: 2.02563214302063 val loss: 2.008418083190918\nsteps: 12500 train loss: 2.0288357734680176 val loss: 1.99904465675354\nsteps: 13000 train loss: 1.999843955039978 val loss: 2.005781650543213\nsteps: 13500 train loss: 1.9971115589141846 val loss: 1.996515154838562\nsteps: 14000 train loss: 2.002121925354004 val loss: 2.0025224685668945\nsteps: 14500 train loss: 2.0197765827178955 val loss: 1.9891889095306396\nsteps: 15000 train loss: 1.9767966270446777 val loss: 1.9887182712554932\nsteps: 15500 train loss: 1.9784421920776367 val loss: 1.9759260416030884\nsteps: 16000 train loss: 1.9777413606643677 val loss: 1.9716285467147827\nsteps: 16500 train loss: 1.9710053205490112 val loss: 1.9605721235275269\nsteps: 17000 train loss: 1.9777494668960571 val loss: 1.9717917442321777\nsteps: 17500 train loss: 1.9646384716033936 val loss: 1.9535588026046753\nsteps: 18000 train loss: 1.9608670473098755 val loss: 1.9471306800842285\nsteps: 18500 train loss: 1.9838298559188843 val loss: 1.9807745218276978\nsteps: 19000 train loss: 1.9511932134628296 val loss: 1.9673123359680176\nsteps: 19500 train loss: 1.9674519300460815 val loss: 1.9525458812713623\nsteps: 20000 train loss: 1.9578638076782227 val loss: 1.9406377077102661\nsteps: 20500 train loss: 1.950528621673584 val loss: 1.9392950534820557\nsteps: 21000 train loss: 1.9427716732025146 val loss: 1.9365723133087158\nsteps: 21500 train loss: 1.9283478260040283 val loss: 1.9317525625228882\nsteps: 22000 train loss: 1.9369611740112305 val loss: 1.9186187982559204\nsteps: 22500 train loss: 1.9220701456069946 val loss: 1.9050339460372925\nsteps: 23000 train loss: 1.9411240816116333 val loss: 1.9121382236480713\nsteps: 23500 train loss: 1.919235348701477 val loss: 1.9375054836273193\nsteps: 24000 train loss: 1.9363641738891602 val loss: 1.9262714385986328\nsteps: 24500 train loss: 1.9174232482910156 val loss: 1.921703815460205\nsteps: 25000 train loss: 1.9425348043441772 val loss: 1.9262514114379883\nsteps: 25500 train loss: 1.9192837476730347 val loss: 1.9291620254516602\nsteps: 26000 train loss: 1.911470890045166 val loss: 1.9039479494094849\nsteps: 26500 train loss: 1.90956711769104 val loss: 1.9192978143692017\nsteps: 27000 train loss: 1.9092040061950684 val loss: 1.9145811796188354\nsteps: 27500 train loss: 1.8976832628250122 val loss: 1.9021618366241455\nsteps: 28000 train loss: 1.9172488451004028 val loss: 1.9018203020095825\nsteps: 28500 train loss: 1.8899385929107666 val loss: 1.9003803730010986\nsteps: 29000 train loss: 1.8895589113235474 val loss: 1.9010026454925537\nsteps: 29500 train loss: 1.8962063789367676 val loss: 1.9074710607528687\nsteps: 30000 train loss: 1.8713120222091675 val loss: 1.909914255142212\nsteps: 30500 train loss: 1.88507080078125 val loss: 1.8872672319412231\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m xb \u001b[38;5;241m=\u001b[39m xb\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m yb \u001b[38;5;241m=\u001b[39m yb\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 12\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[0;32m/kaggle/working/Mixture-of-LLM-Expert/MoE/moe.py:85\u001b[0m, in \u001b[0;36mSparseMoELanguageModel.forward\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m     83\u001b[0m pos_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_table(torch\u001b[38;5;241m.\u001b[39marange(T, device\u001b[38;5;241m=\u001b[39mdevice)) \u001b[38;5;66;03m# (T,C)\u001b[39;00m\n\u001b[1;32m     84\u001b[0m x \u001b[38;5;241m=\u001b[39m tok_emb \u001b[38;5;241m+\u001b[39m pos_emb \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[1;32m     86\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_f(x) \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[1;32m     87\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(x) \u001b[38;5;66;03m# (B,T,vocab_size)\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/kaggle/working/Mixture-of-LLM-Expert/MoE/moe.py:60\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 60\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msa\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmoe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln2(x))\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/kaggle/working/Mixture-of-LLM-Expert/MoE/blocks.py:45\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 45\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([h(x) \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     46\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(out))\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n","File \u001b[0;32m/kaggle/working/Mixture-of-LLM-Expert/MoE/blocks.py:45\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 45\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[43mh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     46\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(out))\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/kaggle/working/Mixture-of-LLM-Expert/MoE/blocks.py:23\u001b[0m, in \u001b[0;36mHead.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m B,T,C \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     22\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey(x)   \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# compute attention scores (\"affinities\")\u001b[39;00m\n\u001b[1;32m     25\u001b[0m wei \u001b[38;5;241m=\u001b[39m q \u001b[38;5;241m@\u001b[39m k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m C\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;66;03m# (B, T, C) @ (B, C, T) -> (B, T, T)\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"context = torch.zeros((1,1), dtype=torch.long, device=device)\ngenerated_word = model.generate(context, max_new_tokens=50)\nseq = \" Batman is the \"\nfor i in generated_word.tolist():\n    seq = seq + \"\"+tokenizer.detokenize(i)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T16:12:34.293977Z","iopub.execute_input":"2024-07-29T16:12:34.295302Z","iopub.status.idle":"2024-07-29T16:12:37.106795Z","shell.execute_reply.started":"2024-07-29T16:12:34.295259Z","shell.execute_reply":"2024-07-29T16:12:37.105930Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"seq","metadata":{"execution":{"iopub.status.busy":"2024-07-29T16:12:37.108231Z","iopub.execute_input":"2024-07-29T16:12:37.108537Z","iopub.status.idle":"2024-07-29T16:12:37.114133Z","shell.execute_reply.started":"2024-07-29T16:12:37.108512Z","shell.execute_reply":"2024-07-29T16:12:37.113218Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"' Batman is the avy Safle irzistmilittin secy h Careven,hites  Uthr'"},"metadata":{}}]},{"cell_type":"code","source":"context","metadata":{"execution":{"iopub.status.busy":"2024-07-29T16:12:37.115321Z","iopub.execute_input":"2024-07-29T16:12:37.115754Z","iopub.status.idle":"2024-07-29T16:12:37.125284Z","shell.execute_reply.started":"2024-07-29T16:12:37.115717Z","shell.execute_reply":"2024-07-29T16:12:37.124497Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"tensor([[0]], device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}