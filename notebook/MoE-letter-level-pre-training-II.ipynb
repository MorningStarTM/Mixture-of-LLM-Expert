{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\github_clone\\\\Mixture-of-LLM-Expert'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from MoE import SparseMoELanguageModel, kaiming_init_weights\n",
    "from Utils import model_params\n",
    "from Tokenizer import WordLevelTokenizer, extract_and_save_text, LetterLevelTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n",
    "max_iters = 50000\n",
    "learning_rate = 3e-4\n",
    "block_size = 8\n",
    "batch_size = 8\n",
    "eval_iters = 500\n",
    "n_emb = 384\n",
    "n_layers = 6\n",
    "n_head = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'data\\\\newspaper-text-summarization-cnn-dailymail\\\\cnn_dailymail\\\\test.csv'  # Replace with your CSV file path\n",
    "output_directory = 'data\\\\'  # Replace with your desired output directory\n",
    "\n",
    "extract_and_save_text(csv_file_path, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data\\\\summaries.txt\", \"rb\") as txt:\n",
    "    texts = txt.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"#$%&'()*+,-./0123456789:;=?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz £¥°´·½ÂáãäåçèéëíîïñóöûüćčēłŠšž​‎–—‘’“”…€\n",
      "129\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(texts.decode())))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LetterLevelTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: [34, 12, 94, 19, 7, 4, 94, 41, 17, 4, 18, 8, 3, 4, 13, 19, 94, 14, 5, 94, 19, 7, 4, 94, 26, 12, 4, 17, 8, 2, 0, 75]\n",
      "Detokenized text: Im the President of the America.\n"
     ]
    }
   ],
   "source": [
    "temp = \"Im the President of the America.\"\n",
    "\n",
    "tokens = tokenizer.tokenize(temp)\n",
    "print(\"Tokens:\", tokens)  # Output: Tokens: [index values representing each word]\n",
    "\n",
    "original_text = tokenizer.detokenize(tokens)\n",
    "print(\"Detokenized text:\", original_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tokenizer.tokenize(texts.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3545403]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "encoded_data = torch.tensor(data, dtype=torch.long)\n",
    "print(encoded_data.shape, encoded_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens : 3190862  --- Validation tokens : 354541\n"
     ]
    }
   ],
   "source": [
    "n = int(0.9*len(encoded_data))\n",
    "train_data = encoded_data[:n]\n",
    "val_data = encoded_data[n:]\n",
    "\n",
    "print(f\"Training tokens : {len(train_data)}  --- Validation tokens : {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([30]) the target: 23\n",
      "when input is tensor([30, 23]) the target: 15\n",
      "when input is tensor([30, 23, 15]) the target: 4\n",
      "when input is tensor([30, 23, 15,  4]) the target: 17\n",
      "when input is tensor([30, 23, 15,  4, 17]) the target: 19\n",
      "when input is tensor([30, 23, 15,  4, 17, 19]) the target: 18\n",
      "when input is tensor([30, 23, 15,  4, 17, 19, 18]) the target: 94\n",
      "when input is tensor([30, 23, 15,  4, 17, 19, 18, 94]) the target: 16\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: \n",
      "tensor([[ 6, 17, 24, 68, 73, 94,  2, 14],\n",
      "        [ 4,  4, 13, 94, 19, 14, 94, 21],\n",
      "        [13,  3, 18,  7,  8, 15, 94,  2],\n",
      "        [11,  8, 13,  6, 94, 58, 74, 24],\n",
      "        [ 7, 17,  4,  4, 94,  0, 11, 11],\n",
      "        [24, 94,  8, 13, 94,  2, 14, 13],\n",
      "        [ 3, 94, 14, 19,  7,  4, 17, 94],\n",
      "        [ 3,  4, 94,  8, 13, 94, 48,  8]])\n",
      "Targets: \n",
      "tensor([[17, 24, 68, 73, 94,  2, 14, 20],\n",
      "        [ 4, 13, 94, 19, 14, 94, 21,  8],\n",
      "        [ 3, 18,  7,  8, 15, 94,  2,  7],\n",
      "        [ 8, 13,  6, 94, 58, 74, 24,  4],\n",
      "        [17,  4,  4, 94,  0, 11, 11,  4],\n",
      "        [94,  8, 13, 94,  2, 14, 13, 13],\n",
      "        [94, 14, 19,  7,  4, 17, 94,  0],\n",
      "        [ 4, 94,  8, 13, 94, 48,  8, 13]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(encoded_data) - block_size, (batch_size,))\n",
    "    x = torch.stack([encoded_data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([encoded_data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print(\"Inputs: \")\n",
    "print(xb)\n",
    "print(\"Targets: \")\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseMoELanguageModel(\n",
       "  (token_embedding_table): Embedding(129, 368)\n",
       "  (position_embedding_table): Embedding(32, 368)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-7): 8 x Head(\n",
       "            (key): Linear(in_features=368, out_features=46, bias=False)\n",
       "            (query): Linear(in_features=368, out_features=46, bias=False)\n",
       "            (value): Linear(in_features=368, out_features=46, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=368, out_features=368, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (smoe): SparseMoE(\n",
       "        (router): NoisyTopkRouter(\n",
       "          (topkroute_linear): Linear(in_features=368, out_features=8, bias=True)\n",
       "          (noise_linear): Linear(in_features=368, out_features=8, bias=True)\n",
       "        )\n",
       "        (experts): ModuleList(\n",
       "          (0-7): 8 x Expert(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=368, out_features=1472, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=1472, out_features=368, bias=True)\n",
       "              (3): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-7): 8 x Head(\n",
       "            (key): Linear(in_features=368, out_features=46, bias=False)\n",
       "            (query): Linear(in_features=368, out_features=46, bias=False)\n",
       "            (value): Linear(in_features=368, out_features=46, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=368, out_features=368, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (smoe): SparseMoE(\n",
       "        (router): NoisyTopkRouter(\n",
       "          (topkroute_linear): Linear(in_features=368, out_features=8, bias=True)\n",
       "          (noise_linear): Linear(in_features=368, out_features=8, bias=True)\n",
       "        )\n",
       "        (experts): ModuleList(\n",
       "          (0-7): 8 x Expert(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=368, out_features=1472, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=1472, out_features=368, bias=True)\n",
       "              (3): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-7): 8 x Head(\n",
       "            (key): Linear(in_features=368, out_features=46, bias=False)\n",
       "            (query): Linear(in_features=368, out_features=46, bias=False)\n",
       "            (value): Linear(in_features=368, out_features=46, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=368, out_features=368, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (smoe): SparseMoE(\n",
       "        (router): NoisyTopkRouter(\n",
       "          (topkroute_linear): Linear(in_features=368, out_features=8, bias=True)\n",
       "          (noise_linear): Linear(in_features=368, out_features=8, bias=True)\n",
       "        )\n",
       "        (experts): ModuleList(\n",
       "          (0-7): 8 x Expert(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=368, out_features=1472, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=1472, out_features=368, bias=True)\n",
       "              (3): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-7): 8 x Head(\n",
       "            (key): Linear(in_features=368, out_features=46, bias=False)\n",
       "            (query): Linear(in_features=368, out_features=46, bias=False)\n",
       "            (value): Linear(in_features=368, out_features=46, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=368, out_features=368, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (smoe): SparseMoE(\n",
       "        (router): NoisyTopkRouter(\n",
       "          (topkroute_linear): Linear(in_features=368, out_features=8, bias=True)\n",
       "          (noise_linear): Linear(in_features=368, out_features=8, bias=True)\n",
       "        )\n",
       "        (experts): ModuleList(\n",
       "          (0-7): 8 x Expert(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=368, out_features=1472, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=1472, out_features=368, bias=True)\n",
       "              (3): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-7): 8 x Head(\n",
       "            (key): Linear(in_features=368, out_features=46, bias=False)\n",
       "            (query): Linear(in_features=368, out_features=46, bias=False)\n",
       "            (value): Linear(in_features=368, out_features=46, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=368, out_features=368, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (smoe): SparseMoE(\n",
       "        (router): NoisyTopkRouter(\n",
       "          (topkroute_linear): Linear(in_features=368, out_features=8, bias=True)\n",
       "          (noise_linear): Linear(in_features=368, out_features=8, bias=True)\n",
       "        )\n",
       "        (experts): ModuleList(\n",
       "          (0-7): 8 x Expert(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=368, out_features=1472, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=1472, out_features=368, bias=True)\n",
       "              (3): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-7): 8 x Head(\n",
       "            (key): Linear(in_features=368, out_features=46, bias=False)\n",
       "            (query): Linear(in_features=368, out_features=46, bias=False)\n",
       "            (value): Linear(in_features=368, out_features=46, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=368, out_features=368, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (smoe): SparseMoE(\n",
       "        (router): NoisyTopkRouter(\n",
       "          (topkroute_linear): Linear(in_features=368, out_features=8, bias=True)\n",
       "          (noise_linear): Linear(in_features=368, out_features=8, bias=True)\n",
       "        )\n",
       "        (experts): ModuleList(\n",
       "          (0-7): 8 x Expert(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=368, out_features=1472, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=1472, out_features=368, bias=True)\n",
       "              (3): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (6): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-7): 8 x Head(\n",
       "            (key): Linear(in_features=368, out_features=46, bias=False)\n",
       "            (query): Linear(in_features=368, out_features=46, bias=False)\n",
       "            (value): Linear(in_features=368, out_features=46, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=368, out_features=368, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (smoe): SparseMoE(\n",
       "        (router): NoisyTopkRouter(\n",
       "          (topkroute_linear): Linear(in_features=368, out_features=8, bias=True)\n",
       "          (noise_linear): Linear(in_features=368, out_features=8, bias=True)\n",
       "        )\n",
       "        (experts): ModuleList(\n",
       "          (0-7): 8 x Expert(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=368, out_features=1472, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=1472, out_features=368, bias=True)\n",
       "              (3): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (7): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-7): 8 x Head(\n",
       "            (key): Linear(in_features=368, out_features=46, bias=False)\n",
       "            (query): Linear(in_features=368, out_features=46, bias=False)\n",
       "            (value): Linear(in_features=368, out_features=46, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=368, out_features=368, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (smoe): SparseMoE(\n",
       "        (router): NoisyTopkRouter(\n",
       "          (topkroute_linear): Linear(in_features=368, out_features=8, bias=True)\n",
       "          (noise_linear): Linear(in_features=368, out_features=8, bias=True)\n",
       "        )\n",
       "        (experts): ModuleList(\n",
       "          (0-7): 8 x Expert(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=368, out_features=1472, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=1472, out_features=368, bias=True)\n",
       "              (3): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n",
       "  (lm_head): Linear(in_features=368, out_features=129, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SparseMoELanguageModel(vocab_size)\n",
    "model.apply(kaiming_init_weights)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 73,957,953\n",
      "Trainable parameters: 73,957,953\n",
      "Non-trainable parameters: 0\n"
     ]
    }
   ],
   "source": [
    "model_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"artifacts\\\\moe_letter.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps: 0 train loss: 1.7906030416488647 val loss: 1.7880699634552002\n",
      "steps: 500 train loss: 1.7752532958984375 val loss: 1.7943099737167358\n",
      "steps: 1000 train loss: 1.8008266687393188 val loss: 1.7749654054641724\n",
      "steps: 1500 train loss: 1.7791913747787476 val loss: 1.790455937385559\n",
      "steps: 2000 train loss: 1.7828686237335205 val loss: 1.7805771827697754\n",
      "steps: 2500 train loss: 1.7928262948989868 val loss: 1.7890949249267578\n",
      "steps: 3000 train loss: 1.7880144119262695 val loss: 1.7864348888397217\n",
      "steps: 3500 train loss: 1.787495732307434 val loss: 1.7963354587554932\n",
      "steps: 4000 train loss: 1.7789260149002075 val loss: 1.788208246231079\n",
      "steps: 4500 train loss: 1.8000684976577759 val loss: 1.7892231941223145\n",
      "steps: 5000 train loss: 1.7860368490219116 val loss: 1.7869511842727661\n",
      "steps: 5500 train loss: 1.7726569175720215 val loss: 1.7985844612121582\n",
      "steps: 6000 train loss: 1.7641535997390747 val loss: 1.7824293375015259\n",
      "steps: 6500 train loss: 1.7796521186828613 val loss: 1.7876641750335693\n",
      "steps: 7000 train loss: 1.7799921035766602 val loss: 1.7844496965408325\n",
      "steps: 7500 train loss: 1.7866007089614868 val loss: 1.7938916683197021\n",
      "steps: 8000 train loss: 1.772718071937561 val loss: 1.7966697216033936\n",
      "steps: 8500 train loss: 1.7776901721954346 val loss: 1.7831693887710571\n",
      "steps: 9000 train loss: 1.776699185371399 val loss: 1.778079867362976\n",
      "steps: 9500 train loss: 1.7693395614624023 val loss: 1.7931071519851685\n",
      "steps: 10000 train loss: 1.7708631753921509 val loss: 1.7909517288208008\n",
      "steps: 10500 train loss: 1.7796075344085693 val loss: 1.7835923433303833\n",
      "steps: 11000 train loss: 1.795418620109558 val loss: 1.7834018468856812\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m xb \u001b[38;5;241m=\u001b[39m xb\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     10\u001b[0m yb \u001b[38;5;241m=\u001b[39m yb\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 12\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32me:\\github_clone\\Mixture-of-LLM-Expert\\MoE\\moe.py:85\u001b[0m, in \u001b[0;36mSparseMoELanguageModel.forward\u001b[1;34m(self, idx, targets)\u001b[0m\n\u001b[0;32m     83\u001b[0m pos_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_table(torch\u001b[38;5;241m.\u001b[39marange(T, device\u001b[38;5;241m=\u001b[39mdevice)) \u001b[38;5;66;03m# (T,C)\u001b[39;00m\n\u001b[0;32m     84\u001b[0m x \u001b[38;5;241m=\u001b[39m tok_emb \u001b[38;5;241m+\u001b[39m pos_emb \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[0;32m     86\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_f(x) \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[0;32m     87\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(x) \u001b[38;5;66;03m# (B,T,vocab_size)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ernest\\.conda\\envs\\l2rpn-test\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Ernest\\.conda\\envs\\l2rpn-test\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Ernest\\.conda\\envs\\l2rpn-test\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\github_clone\\Mixture-of-LLM-Expert\\MoE\\moe.py:60\u001b[0m, in \u001b[0;36mBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 60\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msa\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmoe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln2(x))\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Ernest\\.conda\\envs\\l2rpn-test\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\github_clone\\Mixture-of-LLM-Expert\\MoE\\blocks.py:45\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 45\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([h(x) \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     46\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(out))\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32me:\\github_clone\\Mixture-of-LLM-Expert\\MoE\\blocks.py:45\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 45\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[43mh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     46\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(out))\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Ernest\\.conda\\envs\\l2rpn-test\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\github_clone\\Mixture-of-LLM-Expert\\MoE\\blocks.py:22\u001b[0m, in \u001b[0;36mHead.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     21\u001b[0m     B,T,C \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m---> 22\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery(x) \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# compute attention scores (\"affinities\")\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ernest\\.conda\\envs\\l2rpn-test\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Ernest\\.conda\\envs\\l2rpn-test\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    if iter % eval_iters == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"steps: {iter} train loss: {losses['train']} val loss: {losses['val']}\")\n",
    "        \n",
    "    xb, yb = get_batch('train')\n",
    "    xb = xb.to(device)\n",
    "    yb = yb.to(device)\n",
    "\n",
    "    logits, loss = model.forward(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 726 + 76 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"I lov\"\n",
    "x_data = torch.tensor([tokenizer.tokenize(context)], dtype=torch.long, device=device)\n",
    "generated_word = model.generate(x_data, max_new_tokens=50)\n",
    "seq = \" \"\n",
    "for i in generated_word.tolist():\n",
    "    seq = seq + \"\"+tokenizer.detokenize(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I lover attungaitary,.in .Psagnd hede ttts memenitre .C'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"artifacts\\\\moe_letter.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "l2rpn-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
