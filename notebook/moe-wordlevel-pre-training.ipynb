{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/MorningStarTM/Mixture-of-LLM-Expert.git","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:55:44.691418Z","iopub.execute_input":"2024-08-02T05:55:44.691816Z","iopub.status.idle":"2024-08-02T05:55:46.306513Z","shell.execute_reply.started":"2024-08-02T05:55:44.691783Z","shell.execute_reply":"2024-08-02T05:55:46.305140Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'Mixture-of-LLM-Expert'...\nremote: Enumerating objects: 109, done.\u001b[K\nremote: Counting objects: 100% (109/109), done.\u001b[K\nremote: Compressing objects: 100% (64/64), done.\u001b[K\nremote: Total 109 (delta 46), reused 96 (delta 40), pack-reused 0\u001b[K\nReceiving objects: 100% (109/109), 33.08 KiB | 5.51 MiB/s, done.\nResolving deltas: 100% (46/46), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/working/Mixture-of-LLM-Expert","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:55:46.309498Z","iopub.execute_input":"2024-08-02T05:55:46.310510Z","iopub.status.idle":"2024-08-02T05:55:46.318736Z","shell.execute_reply.started":"2024-08-02T05:55:46.310454Z","shell.execute_reply":"2024-08-02T05:55:46.317581Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/working/Mixture-of-LLM-Expert\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:55:46.320165Z","iopub.execute_input":"2024-08-02T05:55:46.320530Z","iopub.status.idle":"2024-08-02T05:55:47.530353Z","shell.execute_reply.started":"2024-08-02T05:55:46.320496Z","shell.execute_reply":"2024-08-02T05:55:47.528939Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"LICENSE  MoE  Models  README.md  Tokenizer  Utils  data  notebook\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport re\nimport json\nfrom MoE import SparseMoELanguageModel, kaiming_init_weights\nfrom Utils import model_params\nfrom Tokenizer import WordLevelTokenizer, extract_and_save_text, LetterLevelTokenizer\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:55:53.642608Z","iopub.execute_input":"2024-08-02T05:55:53.643039Z","iopub.status.idle":"2024-08-02T05:55:57.667539Z","shell.execute_reply.started":"2024-08-02T05:55:53.643003Z","shell.execute_reply":"2024-08-02T05:55:57.666399Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice\nmax_iters = 100000\nlearning_rate = 3e-4\nblock_size = 16\nbatch_size = 16\neval_iters = 500\nn_emb = 384\nn_layers = 6\nn_head = 6","metadata":{"execution":{"iopub.status.busy":"2024-08-02T09:56:33.876078Z","iopub.execute_input":"2024-08-02T09:56:33.877401Z","iopub.status.idle":"2024-08-02T09:56:33.882692Z","shell.execute_reply.started":"2024-08-02T09:56:33.877363Z","shell.execute_reply":"2024-08-02T09:56:33.881656Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"# Utility Function","metadata":{}},{"cell_type":"code","source":"def get_vocab_size(corpus):\n    \"\"\"\n    Get the vocabulary size of the given corpus.\n\n    Parameters:\n    corpus (str): The text corpus to analyze.\n\n    Returns:\n    int: The size of the vocabulary (number of unique words and punctuation).\n    \"\"\"\n    words = preprocess_text(corpus)\n    unique_words = set(words)\n    return len(unique_words)\n\ndef preprocess_text(text):\n    \"\"\"\n    Preprocess the text by converting to lowercase and splitting into words and punctuation.\n\n    Parameters:\n    text (str): The text to preprocess.\n\n    Returns:\n    list: A list of words and punctuation.\n    \"\"\"\n    text = text.lower()\n    words = re.findall(r'\\b\\w+\\b|[^\\w\\s]', text)\n    return words","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:56:55.121815Z","iopub.execute_input":"2024-08-02T05:56:55.122237Z","iopub.status.idle":"2024-08-02T05:56:55.131310Z","shell.execute_reply.started":"2024-08-02T05:56:55.122194Z","shell.execute_reply":"2024-08-02T05:56:55.130336Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Get Data","metadata":{}},{"cell_type":"code","source":"csv_file_path = '/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv'  # Replace with your CSV file path\noutput_directory = '/kaggle/working/'  # Replace with your desired output directory\n\nextract_and_save_text(csv_file_path, output_directory)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:56:19.131961Z","iopub.execute_input":"2024-08-02T05:56:19.132383Z","iopub.status.idle":"2024-08-02T05:56:20.421837Z","shell.execute_reply.started":"2024-08-02T05:56:19.132350Z","shell.execute_reply":"2024-08-02T05:56:20.420825Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"with open(\"/kaggle/working/articles.txt\", \"rb\") as txt:\n    texts = txt.read()","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:56:26.297914Z","iopub.execute_input":"2024-08-02T05:56:26.298360Z","iopub.status.idle":"2024-08-02T05:56:26.329027Z","shell.execute_reply.started":"2024-08-02T05:56:26.298328Z","shell.execute_reply":"2024-08-02T05:56:26.327839Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Token","metadata":{}},{"cell_type":"code","source":"texts_token = texts.decode()\ntexts_token_ount = texts_token.split()\nlen(texts_token_ount)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:57:05.133294Z","iopub.execute_input":"2024-08-02T05:57:05.133695Z","iopub.status.idle":"2024-08-02T05:57:06.153745Z","shell.execute_reply.started":"2024-08-02T05:57:05.133666Z","shell.execute_reply":"2024-08-02T05:57:06.152643Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"7853548"},"metadata":{}}]},{"cell_type":"markdown","source":"# Tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = WordLevelTokenizer()\ntokenizer.fit(texts_token)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:57:14.931356Z","iopub.execute_input":"2024-08-02T05:57:14.932098Z","iopub.status.idle":"2024-08-02T05:57:23.427991Z","shell.execute_reply.started":"2024-08-02T05:57:14.932062Z","shell.execute_reply":"2024-08-02T05:57:23.426769Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"Building Vocabulary: 100%|██████████| 92616/92616 [00:00<00:00, 645516.66it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"temp = \"Im the President of the America.\"\n\ntokens = tokenizer.tokenize(temp)\nprint(\"Tokens:\", tokens)  # Output: Tokens: [index values representing each word]\n\noriginal_text = tokenizer.detokenize(tokens)\nprint(\"Detokenized text:\", original_text)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:57:23.801194Z","iopub.execute_input":"2024-08-02T05:57:23.802171Z","iopub.status.idle":"2024-08-02T05:57:23.808141Z","shell.execute_reply.started":"2024-08-02T05:57:23.802134Z","shell.execute_reply":"2024-08-02T05:57:23.806929Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Tokens: [30574, 743, 37855, 89825, 743, 80881, 63146]\nDetokenized text: im the president of the america .\n","output_type":"stream"}]},{"cell_type":"code","source":"vocab_size = get_vocab_size(texts_token)\nprint(\"Vocabulary Size:\", vocab_size)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:57:40.739457Z","iopub.execute_input":"2024-08-02T05:57:40.739887Z","iopub.status.idle":"2024-08-02T05:57:48.818345Z","shell.execute_reply.started":"2024-08-02T05:57:40.739856Z","shell.execute_reply":"2024-08-02T05:57:48.817260Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Vocabulary Size: 92616\n","output_type":"stream"}]},{"cell_type":"code","source":"data = tokenizer.tokenize(texts_token)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:57:52.371066Z","iopub.execute_input":"2024-08-02T05:57:52.371745Z","iopub.status.idle":"2024-08-02T05:58:02.668779Z","shell.execute_reply.started":"2024-08-02T05:57:52.371713Z","shell.execute_reply":"2024-08-02T05:58:02.667549Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"encoded_data = torch.tensor(data, dtype=torch.long)\nprint(encoded_data.shape, encoded_data.dtype)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:58:02.670658Z","iopub.execute_input":"2024-08-02T05:58:02.671002Z","iopub.status.idle":"2024-08-02T05:58:04.218678Z","shell.execute_reply.started":"2024-08-02T05:58:02.670973Z","shell.execute_reply":"2024-08-02T05:58:04.217657Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"torch.Size([9299088]) torch.int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data Splitting","metadata":{}},{"cell_type":"code","source":"n = int(0.9*len(encoded_data))\ntrain_data = encoded_data[:n]\nval_data = encoded_data[n:]\n\nprint(f\"Training tokens : {len(train_data)}  --- Validation tokens : {len(val_data)}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:58:06.201131Z","iopub.execute_input":"2024-08-02T05:58:06.201567Z","iopub.status.idle":"2024-08-02T05:58:06.222135Z","shell.execute_reply.started":"2024-08-02T05:58:06.201534Z","shell.execute_reply":"2024-08-02T05:58:06.220958Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Training tokens : 8369179  --- Validation tokens : 929909\n","output_type":"stream"}]},{"cell_type":"code","source":"x = train_data[:block_size]\ny = train_data[1:block_size+1]\nfor t in range(block_size):\n    context = x[:t+1]\n    target = y[t]\n    print(f\"when input is {context} the target: {target}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-02T09:56:48.356016Z","iopub.execute_input":"2024-08-02T09:56:48.357042Z","iopub.status.idle":"2024-08-02T09:56:48.369783Z","shell.execute_reply.started":"2024-08-02T09:56:48.356995Z","shell.execute_reply":"2024-08-02T09:56:48.368675Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"when input is tensor([7408]) the target: 84224\nwhen input is tensor([ 7408, 84224]) the target: 41150\nwhen input is tensor([ 7408, 84224, 41150]) the target: 4621\nwhen input is tensor([ 7408, 84224, 41150,  4621]) the target: 32561\nwhen input is tensor([ 7408, 84224, 41150,  4621, 32561]) the target: 45991\nwhen input is tensor([ 7408, 84224, 41150,  4621, 32561, 45991]) the target: 16530\nwhen input is tensor([ 7408, 84224, 41150,  4621, 32561, 45991, 16530]) the target: 60346\nwhen input is tensor([ 7408, 84224, 41150,  4621, 32561, 45991, 16530, 60346]) the target: 40485\nwhen input is tensor([ 7408, 84224, 41150,  4621, 32561, 45991, 16530, 60346, 40485]) the target: 14803\nwhen input is tensor([ 7408, 84224, 41150,  4621, 32561, 45991, 16530, 60346, 40485, 14803]) the target: 24986\nwhen input is tensor([ 7408, 84224, 41150,  4621, 32561, 45991, 16530, 60346, 40485, 14803,\n        24986]) the target: 14803\nwhen input is tensor([ 7408, 84224, 41150,  4621, 32561, 45991, 16530, 60346, 40485, 14803,\n        24986, 14803]) the target: 65738\nwhen input is tensor([ 7408, 84224, 41150,  4621, 32561, 45991, 16530, 60346, 40485, 14803,\n        24986, 14803, 65738]) the target: 34989\nwhen input is tensor([ 7408, 84224, 41150,  4621, 32561, 45991, 16530, 60346, 40485, 14803,\n        24986, 14803, 65738, 34989]) the target: 53097\nwhen input is tensor([ 7408, 84224, 41150,  4621, 32561, 45991, 16530, 60346, 40485, 14803,\n        24986, 14803, 65738, 34989, 53097]) the target: 36700\nwhen input is tensor([ 7408, 84224, 41150,  4621, 32561, 45991, 16530, 60346, 40485, 14803,\n        24986, 14803, 65738, 34989, 53097, 36700]) the target: 89825\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Make Batch","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(1337)\n\ndef get_batch(split):\n    data = train_data if split == \"train\" else val_data\n    ix = torch.randint(len(encoded_data) - block_size, (batch_size,))\n    x = torch.stack([encoded_data[i:i+block_size] for i in ix])\n    y = torch.stack([encoded_data[i+1:i+block_size+1] for i in ix])\n    return x, y\n\nxb, yb = get_batch('train')\nprint(\"Inputs: \")\nprint(xb)\nprint(\"Targets: \")\nprint(yb)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T09:56:51.986646Z","iopub.execute_input":"2024-08-02T09:56:51.987056Z","iopub.status.idle":"2024-08-02T09:56:52.002283Z","shell.execute_reply.started":"2024-08-02T09:56:51.987023Z","shell.execute_reply":"2024-08-02T09:56:52.001155Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Inputs: \ntensor([[26495, 21803, 56851, 34989, 67137, 63701, 56851, 39752, 24842, 63146,\n         77504, 12025, 56851, 83786, 56851, 15472],\n        [ 9802, 63146, 87273, 32970, 70950, 52530, 50030,  1729, 33755, 41643,\n         23606, 89825,   743, 81731, 11086, 33629],\n        [61440,   743, 60047, 11086, 89825, 80361, 65614, 52530, 62673, 39044,\n         66580,  4139, 48181, 70804, 63146,  1385],\n        [75268, 31454, 85994,  1917, 17946, 13026, 59096, 35538, 31454, 81831,\n         48058, 23401, 31196, 33629, 25237, 40074],\n        [76059, 40691, 63146, 10342, 10642, 20368, 56851, 80178, 79601, 43720,\n         34644, 36832, 80467, 11676, 10342, 31454],\n        [37851, 41562, 64369, 31454, 38456, 16562, 89825, 16314, 90578, 52530,\n         62673, 67137,  2855, 53707, 10465, 13204],\n        [63215, 56851, 90850, 34794, 16530, 43581, 56851, 38833, 41562, 87525,\n         50727, 16530, 63257, 16530, 76232, 32138],\n        [70318,  3737, 57708,  2133, 34989,   743, 33275,  1917, 56837, 89825,\n         89157, 47473,  8036,  9975, 16530, 63398],\n        [82861, 63146, 52530, 38272, 61737,  8036, 38833, 74998, 48055, 60148,\n         77770, 24986, 66233, 89157, 10153, 56851],\n        [26425, 13409, 20302, 48055, 63701, 63146, 25309, 36832, 80467, 31196,\n          9107, 24986, 63701, 63146, 45357, 36832],\n        [ 9316, 24944, 16530, 21597, 67707, 18418, 46031, 48055, 32008, 56851,\n         13586, 32323, 63146, 18104, 49271,  9316],\n        [13586, 87636, 63146, 31454, 52530, 88069, 52530, 14778, 13026,   743,\n         85310, 57708,  1875,  4621, 65068, 10342],\n        [32921, 63146,   743, 13609, 57708,  9107, 57708, 42548, 34794, 31454,\n         86488, 83136, 38744, 24986, 34794, 23468],\n        [61050, 12566, 15836,   743, 10780, 89825,   743, 27812, 56851, 65607,\n         48055, 54606, 23431, 35742, 57708, 74083],\n        [57708, 85124, 67790, 32415, 61600, 16530, 35081, 67538, 89825, 70079,\n         52530, 77294, 63146, 81576, 35538, 11951],\n        [38311, 13586, 70905, 37550, 40334, 63146, 91071, 32428, 34794, 31454,\n         64567, 56851, 34989,   743, 49567, 26425]])\nTargets: \ntensor([[21803, 56851, 34989, 67137, 63701, 56851, 39752, 24842, 63146, 77504,\n         12025, 56851, 83786, 56851, 15472, 37234],\n        [63146, 87273, 32970, 70950, 52530, 50030,  1729, 33755, 41643, 23606,\n         89825,   743, 81731, 11086, 33629, 70756],\n        [  743, 60047, 11086, 89825, 80361, 65614, 52530, 62673, 39044, 66580,\n          4139, 48181, 70804, 63146,  1385, 31578],\n        [31454, 85994,  1917, 17946, 13026, 59096, 35538, 31454, 81831, 48058,\n         23401, 31196, 33629, 25237, 40074, 16530],\n        [40691, 63146, 10342, 10642, 20368, 56851, 80178, 79601, 43720, 34644,\n         36832, 80467, 11676, 10342, 31454, 77065],\n        [41562, 64369, 31454, 38456, 16562, 89825, 16314, 90578, 52530, 62673,\n         67137,  2855, 53707, 10465, 13204, 42166],\n        [56851, 90850, 34794, 16530, 43581, 56851, 38833, 41562, 87525, 50727,\n         16530, 63257, 16530, 76232, 32138, 63146],\n        [ 3737, 57708,  2133, 34989,   743, 33275,  1917, 56837, 89825, 89157,\n         47473,  8036,  9975, 16530, 63398, 53890],\n        [63146, 52530, 38272, 61737,  8036, 38833, 74998, 48055, 60148, 77770,\n         24986, 66233, 89157, 10153, 56851, 84303],\n        [13409, 20302, 48055, 63701, 63146, 25309, 36832, 80467, 31196,  9107,\n         24986, 63701, 63146, 45357, 36832, 80467],\n        [24944, 16530, 21597, 67707, 18418, 46031, 48055, 32008, 56851, 13586,\n         32323, 63146, 18104, 49271,  9316, 24944],\n        [87636, 63146, 31454, 52530, 88069, 52530, 14778, 13026,   743, 85310,\n         57708,  1875,  4621, 65068, 10342,  8887],\n        [63146,   743, 13609, 57708,  9107, 57708, 42548, 34794, 31454, 86488,\n         83136, 38744, 24986, 34794, 23468, 44505],\n        [12566, 15836,   743, 10780, 89825,   743, 27812, 56851, 65607, 48055,\n         54606, 23431, 35742, 57708, 74083, 56851],\n        [85124, 67790, 32415, 61600, 16530, 35081, 67538, 89825, 70079, 52530,\n         77294, 63146, 81576, 35538, 11951, 39775],\n        [13586, 70905, 37550, 40334, 63146, 91071, 32428, 34794, 31454, 64567,\n         56851, 34989,   743, 49567, 26425,  5224]])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model - MoE - GPT","metadata":{}},{"cell_type":"code","source":"model = SparseMoELanguageModel(vocab_size)\nmodel.apply(kaiming_init_weights)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:58:43.635100Z","iopub.execute_input":"2024-08-02T05:58:43.635529Z","iopub.status.idle":"2024-08-02T05:58:46.774746Z","shell.execute_reply.started":"2024-08-02T05:58:43.635490Z","shell.execute_reply":"2024-08-02T05:58:46.773755Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"SparseMoELanguageModel(\n  (token_embedding_table): Embedding(92616, 368)\n  (position_embedding_table): Embedding(32, 368)\n  (blocks): Sequential(\n    (0): Block(\n      (sa): MultiHeadAttention(\n        (heads): ModuleList(\n          (0-7): 8 x Head(\n            (key): Linear(in_features=368, out_features=46, bias=False)\n            (query): Linear(in_features=368, out_features=46, bias=False)\n            (value): Linear(in_features=368, out_features=46, bias=False)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (proj): Linear(in_features=368, out_features=368, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (smoe): SparseMoE(\n        (router): NoisyTopkRouter(\n          (topkroute_linear): Linear(in_features=368, out_features=8, bias=True)\n          (noise_linear): Linear(in_features=368, out_features=8, bias=True)\n        )\n        (experts): ModuleList(\n          (0-7): 8 x Expert(\n            (net): Sequential(\n              (0): Linear(in_features=368, out_features=1472, bias=True)\n              (1): ReLU()\n              (2): Linear(in_features=1472, out_features=368, bias=True)\n              (3): Dropout(p=0.2, inplace=False)\n            )\n          )\n        )\n      )\n      (ln1): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n      (ln2): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n    )\n    (1): Block(\n      (sa): MultiHeadAttention(\n        (heads): ModuleList(\n          (0-7): 8 x Head(\n            (key): Linear(in_features=368, out_features=46, bias=False)\n            (query): Linear(in_features=368, out_features=46, bias=False)\n            (value): Linear(in_features=368, out_features=46, bias=False)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (proj): Linear(in_features=368, out_features=368, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (smoe): SparseMoE(\n        (router): NoisyTopkRouter(\n          (topkroute_linear): Linear(in_features=368, out_features=8, bias=True)\n          (noise_linear): Linear(in_features=368, out_features=8, bias=True)\n        )\n        (experts): ModuleList(\n          (0-7): 8 x Expert(\n            (net): Sequential(\n              (0): Linear(in_features=368, out_features=1472, bias=True)\n              (1): ReLU()\n              (2): Linear(in_features=1472, out_features=368, bias=True)\n              (3): Dropout(p=0.2, inplace=False)\n            )\n          )\n        )\n      )\n      (ln1): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n      (ln2): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n    )\n    (2): Block(\n      (sa): MultiHeadAttention(\n        (heads): ModuleList(\n          (0-7): 8 x Head(\n            (key): Linear(in_features=368, out_features=46, bias=False)\n            (query): Linear(in_features=368, out_features=46, bias=False)\n            (value): Linear(in_features=368, out_features=46, bias=False)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (proj): Linear(in_features=368, out_features=368, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (smoe): SparseMoE(\n        (router): NoisyTopkRouter(\n          (topkroute_linear): Linear(in_features=368, out_features=8, bias=True)\n          (noise_linear): Linear(in_features=368, out_features=8, bias=True)\n        )\n        (experts): ModuleList(\n          (0-7): 8 x Expert(\n            (net): Sequential(\n              (0): Linear(in_features=368, out_features=1472, bias=True)\n              (1): ReLU()\n              (2): Linear(in_features=1472, out_features=368, bias=True)\n              (3): Dropout(p=0.2, inplace=False)\n            )\n          )\n        )\n      )\n      (ln1): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n      (ln2): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n    )\n    (3): Block(\n      (sa): MultiHeadAttention(\n        (heads): ModuleList(\n          (0-7): 8 x Head(\n            (key): Linear(in_features=368, out_features=46, bias=False)\n            (query): Linear(in_features=368, out_features=46, bias=False)\n            (value): Linear(in_features=368, out_features=46, bias=False)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (proj): Linear(in_features=368, out_features=368, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (smoe): SparseMoE(\n        (router): NoisyTopkRouter(\n          (topkroute_linear): Linear(in_features=368, out_features=8, bias=True)\n          (noise_linear): Linear(in_features=368, out_features=8, bias=True)\n        )\n        (experts): ModuleList(\n          (0-7): 8 x Expert(\n            (net): Sequential(\n              (0): Linear(in_features=368, out_features=1472, bias=True)\n              (1): ReLU()\n              (2): Linear(in_features=1472, out_features=368, bias=True)\n              (3): Dropout(p=0.2, inplace=False)\n            )\n          )\n        )\n      )\n      (ln1): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n      (ln2): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n    )\n    (4): Block(\n      (sa): MultiHeadAttention(\n        (heads): ModuleList(\n          (0-7): 8 x Head(\n            (key): Linear(in_features=368, out_features=46, bias=False)\n            (query): Linear(in_features=368, out_features=46, bias=False)\n            (value): Linear(in_features=368, out_features=46, bias=False)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (proj): Linear(in_features=368, out_features=368, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (smoe): SparseMoE(\n        (router): NoisyTopkRouter(\n          (topkroute_linear): Linear(in_features=368, out_features=8, bias=True)\n          (noise_linear): Linear(in_features=368, out_features=8, bias=True)\n        )\n        (experts): ModuleList(\n          (0-7): 8 x Expert(\n            (net): Sequential(\n              (0): Linear(in_features=368, out_features=1472, bias=True)\n              (1): ReLU()\n              (2): Linear(in_features=1472, out_features=368, bias=True)\n              (3): Dropout(p=0.2, inplace=False)\n            )\n          )\n        )\n      )\n      (ln1): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n      (ln2): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n    )\n    (5): Block(\n      (sa): MultiHeadAttention(\n        (heads): ModuleList(\n          (0-7): 8 x Head(\n            (key): Linear(in_features=368, out_features=46, bias=False)\n            (query): Linear(in_features=368, out_features=46, bias=False)\n            (value): Linear(in_features=368, out_features=46, bias=False)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (proj): Linear(in_features=368, out_features=368, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (smoe): SparseMoE(\n        (router): NoisyTopkRouter(\n          (topkroute_linear): Linear(in_features=368, out_features=8, bias=True)\n          (noise_linear): Linear(in_features=368, out_features=8, bias=True)\n        )\n        (experts): ModuleList(\n          (0-7): 8 x Expert(\n            (net): Sequential(\n              (0): Linear(in_features=368, out_features=1472, bias=True)\n              (1): ReLU()\n              (2): Linear(in_features=1472, out_features=368, bias=True)\n              (3): Dropout(p=0.2, inplace=False)\n            )\n          )\n        )\n      )\n      (ln1): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n      (ln2): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n    )\n    (6): Block(\n      (sa): MultiHeadAttention(\n        (heads): ModuleList(\n          (0-7): 8 x Head(\n            (key): Linear(in_features=368, out_features=46, bias=False)\n            (query): Linear(in_features=368, out_features=46, bias=False)\n            (value): Linear(in_features=368, out_features=46, bias=False)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (proj): Linear(in_features=368, out_features=368, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (smoe): SparseMoE(\n        (router): NoisyTopkRouter(\n          (topkroute_linear): Linear(in_features=368, out_features=8, bias=True)\n          (noise_linear): Linear(in_features=368, out_features=8, bias=True)\n        )\n        (experts): ModuleList(\n          (0-7): 8 x Expert(\n            (net): Sequential(\n              (0): Linear(in_features=368, out_features=1472, bias=True)\n              (1): ReLU()\n              (2): Linear(in_features=1472, out_features=368, bias=True)\n              (3): Dropout(p=0.2, inplace=False)\n            )\n          )\n        )\n      )\n      (ln1): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n      (ln2): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n    )\n    (7): Block(\n      (sa): MultiHeadAttention(\n        (heads): ModuleList(\n          (0-7): 8 x Head(\n            (key): Linear(in_features=368, out_features=46, bias=False)\n            (query): Linear(in_features=368, out_features=46, bias=False)\n            (value): Linear(in_features=368, out_features=46, bias=False)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (proj): Linear(in_features=368, out_features=368, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (smoe): SparseMoE(\n        (router): NoisyTopkRouter(\n          (topkroute_linear): Linear(in_features=368, out_features=8, bias=True)\n          (noise_linear): Linear(in_features=368, out_features=8, bias=True)\n        )\n        (experts): ModuleList(\n          (0-7): 8 x Expert(\n            (net): Sequential(\n              (0): Linear(in_features=368, out_features=1472, bias=True)\n              (1): ReLU()\n              (2): Linear(in_features=1472, out_features=368, bias=True)\n              (3): Dropout(p=0.2, inplace=False)\n            )\n          )\n        )\n      )\n      (ln1): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n      (ln2): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (ln_f): LayerNorm((368,), eps=1e-05, elementwise_affine=True)\n  (lm_head): Linear(in_features=368, out_features=92616, bias=True)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"# paramters","metadata":{}},{"cell_type":"code","source":"model_params(model)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:58:57.147826Z","iopub.execute_input":"2024-08-02T05:58:57.148503Z","iopub.status.idle":"2024-08-02T05:58:57.160961Z","shell.execute_reply.started":"2024-08-02T05:58:57.148456Z","shell.execute_reply":"2024-08-02T05:58:57.159802Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Total parameters: 142,120,872\nTrainable parameters: 142,120,872\nNon-trainable parameters: 0\n","output_type":"stream"}]},{"cell_type":"code","source":"@torch.no_grad()\ndef estimate_loss():\n    out = {}\n    model.eval()\n    for split in ['train', 'val']:\n        losses = torch.zeros(eval_iters)\n        for k in range(eval_iters):\n            X, Y = get_batch(split)\n            X, Y = X.to(device), Y.to(device)\n            logits, loss = model(X, Y)\n            losses[k] = loss.item()\n        out[split] = losses.mean()\n    model.train()\n    return out","metadata":{"execution":{"iopub.status.busy":"2024-08-02T05:59:04.350577Z","iopub.execute_input":"2024-08-02T05:59:04.350979Z","iopub.status.idle":"2024-08-02T05:59:04.358367Z","shell.execute_reply.started":"2024-08-02T05:59:04.350948Z","shell.execute_reply":"2024-08-02T05:59:04.357189Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n\nfor iter in range(max_iters):\n    if iter % eval_iters == 0:\n        losses = estimate_loss()\n        print(f\"steps: {iter} train loss: {losses['train']} val loss: {losses['val']}\")\n        \n    xb, yb = get_batch('train')\n    xb = xb.to(device)\n    yb = yb.to(device)\n\n    logits, loss = model.forward(xb, yb)\n    optimizer.zero_grad(set_to_none=True)\n    loss.backward()\n    optimizer.step()\nprint(loss.item())","metadata":{"execution":{"iopub.status.busy":"2024-08-02T09:57:06.367271Z","iopub.execute_input":"2024-08-02T09:57:06.367667Z","iopub.status.idle":"2024-08-02T12:18:32.705128Z","shell.execute_reply.started":"2024-08-02T09:57:06.367635Z","shell.execute_reply":"2024-08-02T12:18:32.703785Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"steps: 0 train loss: 6.6596150398254395 val loss: 6.624687671661377\nsteps: 500 train loss: 5.746845245361328 val loss: 5.752355575561523\nsteps: 1000 train loss: 5.695250988006592 val loss: 5.673673629760742\nsteps: 1500 train loss: 5.664629936218262 val loss: 5.6663336753845215\nsteps: 2000 train loss: 5.650763511657715 val loss: 5.627066612243652\nsteps: 2500 train loss: 5.626317977905273 val loss: 5.630195617675781\nsteps: 3000 train loss: 5.609336853027344 val loss: 5.60875940322876\nsteps: 3500 train loss: 5.582660675048828 val loss: 5.58222770690918\nsteps: 4000 train loss: 5.552610397338867 val loss: 5.548210620880127\nsteps: 4500 train loss: 5.531296730041504 val loss: 5.5355544090271\nsteps: 5000 train loss: 5.532628059387207 val loss: 5.516678810119629\nsteps: 5500 train loss: 5.502021789550781 val loss: 5.493224620819092\nsteps: 6000 train loss: 5.503291606903076 val loss: 5.475855350494385\nsteps: 6500 train loss: 5.458742618560791 val loss: 5.487979888916016\nsteps: 7000 train loss: 5.4576520919799805 val loss: 5.471889019012451\nsteps: 7500 train loss: 5.45754861831665 val loss: 5.470639705657959\nsteps: 8000 train loss: 5.416844844818115 val loss: 5.410842418670654\nsteps: 8500 train loss: 5.43179178237915 val loss: 5.4209303855896\nsteps: 9000 train loss: 5.398992538452148 val loss: 5.404892921447754\nsteps: 9500 train loss: 5.390255451202393 val loss: 5.395816802978516\nsteps: 10000 train loss: 5.3735151290893555 val loss: 5.359447956085205\nsteps: 10500 train loss: 5.3827667236328125 val loss: 5.392414569854736\nsteps: 11000 train loss: 5.33988094329834 val loss: 5.347405433654785\nsteps: 11500 train loss: 5.334079742431641 val loss: 5.347385883331299\nsteps: 12000 train loss: 5.316866874694824 val loss: 5.3477959632873535\nsteps: 12500 train loss: 5.340978622436523 val loss: 5.324483394622803\nsteps: 13000 train loss: 5.296107292175293 val loss: 5.3103742599487305\nsteps: 13500 train loss: 5.309937477111816 val loss: 5.304811954498291\nsteps: 14000 train loss: 5.2997918128967285 val loss: 5.274380683898926\nsteps: 14500 train loss: 5.295175075531006 val loss: 5.284912586212158\nsteps: 15000 train loss: 5.296398639678955 val loss: 5.267688274383545\nsteps: 15500 train loss: 5.2660393714904785 val loss: 5.2771406173706055\nsteps: 16000 train loss: 5.2526044845581055 val loss: 5.2455620765686035\nsteps: 16500 train loss: 5.268585681915283 val loss: 5.236912250518799\nsteps: 17000 train loss: 5.2419891357421875 val loss: 5.246074676513672\nsteps: 17500 train loss: 5.253296375274658 val loss: 5.234894752502441\nsteps: 18000 train loss: 5.220344066619873 val loss: 5.223904132843018\nsteps: 18500 train loss: 5.232182502746582 val loss: 5.228915214538574\nsteps: 19000 train loss: 5.227654457092285 val loss: 5.187376022338867\nsteps: 19500 train loss: 5.216614723205566 val loss: 5.213146686553955\nsteps: 20000 train loss: 5.204725742340088 val loss: 5.190825939178467\nsteps: 20500 train loss: 5.184802055358887 val loss: 5.183037757873535\nsteps: 21000 train loss: 5.164486885070801 val loss: 5.194990158081055\nsteps: 21500 train loss: 5.180142402648926 val loss: 5.178062438964844\nsteps: 22000 train loss: 5.1576642990112305 val loss: 5.174079895019531\nsteps: 22500 train loss: 5.182373523712158 val loss: 5.171118259429932\nsteps: 23000 train loss: 5.156698703765869 val loss: 5.169436931610107\nsteps: 23500 train loss: 5.133561611175537 val loss: 5.157064437866211\nsteps: 24000 train loss: 5.155276298522949 val loss: 5.159709453582764\nsteps: 24500 train loss: 5.125313758850098 val loss: 5.149606227874756\nsteps: 25000 train loss: 5.12283182144165 val loss: 5.130547523498535\nsteps: 25500 train loss: 5.136058807373047 val loss: 5.1233062744140625\nsteps: 26000 train loss: 5.105408191680908 val loss: 5.132386207580566\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m     logits, loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(xb, yb)\n\u001b[1;32m     13\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 14\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss\u001b[38;5;241m.\u001b[39mitem())\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"model_path = '/kaggle/working/MoE_W7M.pth'\ntorch.save(model.state_dict(), model_path)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:20:31.045305Z","iopub.execute_input":"2024-08-02T12:20:31.045685Z","iopub.status.idle":"2024-08-02T12:20:32.081013Z","shell.execute_reply.started":"2024-08-02T12:20:31.045655Z","shell.execute_reply":"2024-08-02T12:20:32.079884Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"context = torch.zeros((1,1), dtype=torch.long, device=device)\ngenerated_word = model.generate(context, max_new_tokens=50)\nseq = \" Batman is the \"\nfor i in generated_word.tolist():\n    seq = seq + \"\"+tokenizer.detokenize(i)","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:35.562046Z","iopub.execute_input":"2024-08-02T12:18:35.563009Z","iopub.status.idle":"2024-08-02T12:18:38.638693Z","shell.execute_reply.started":"2024-08-02T12:18:35.562969Z","shell.execute_reply":"2024-08-02T12:18:38.637609Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"seq","metadata":{"execution":{"iopub.status.busy":"2024-08-02T12:18:40.592481Z","iopub.execute_input":"2024-08-02T12:18:40.592888Z","iopub.status.idle":"2024-08-02T12:18:40.599505Z","shell.execute_reply.started":"2024-08-02T12:18:40.592855Z","shell.execute_reply":"2024-08-02T12:18:40.598378Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"\" Batman is the godiva carson , 23 , all spoke to his sister and his nine - year - old new wife drew wardrobe boots left son soon , telling pal gerrard , said with , instagram resurrected xia chlebowski on deck indicated me launched costumed blowing ' ' ' , 66 moore enough\""},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}